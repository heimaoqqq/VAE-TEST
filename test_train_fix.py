#!/usr/bin/env python3
"""
æµ‹è¯•è®­ç»ƒè„šæœ¬ä¿®å¤ - ç®€åŒ–ç‰ˆæœ¬
"""

import torch
from diffusers import VQModel, UNet2DModel, DDPMScheduler
from accelerate import Accelerator
import os

def test_training_fix():
    print("ğŸ§ª æµ‹è¯•è®­ç»ƒè„šæœ¬ä¿®å¤...")
    
    # æ¨¡æ‹Ÿè®­ç»ƒå‚æ•°
    class Args:
        mixed_precision = "fp16"
        
    args = Args()
    
    # åˆå§‹åŒ–accelerator
    accelerator = Accelerator(mixed_precision=args.mixed_precision)
    print(f"Mixed precision: {accelerator.mixed_precision}")
    
    try:
        # åŠ è½½æ¨¡å‹
        print("åŠ è½½æ¨¡å‹...")
        vae = VQModel.from_pretrained("CompVis/ldm-celebahq-256", subfolder="vqvae")
        
        # åˆ›å»ºç®€å•çš„UNetç”¨äºæµ‹è¯•
        unet = UNet2DModel(
            sample_size=64,
            in_channels=3,
            out_channels=3,
            layers_per_block=2,
            block_out_channels=(128, 256),
            down_block_types=("DownBlock2D", "AttnDownBlock2D"),
            up_block_types=("AttnUpBlock2D", "UpBlock2D"),
        )
        
        # åˆ›å»ºä¼˜åŒ–å™¨å’Œè°ƒåº¦å™¨
        optimizer = torch.optim.AdamW(unet.parameters(), lr=1e-4)
        noise_scheduler = DDPMScheduler(num_train_timesteps=1000)
        
        # å‡†å¤‡æ¨¡å‹ï¼ˆåº”ç”¨æ··åˆç²¾åº¦ï¼‰
        print("å‡†å¤‡æ¨¡å‹...")
        unet, vae, optimizer = accelerator.prepare(unet, vae, optimizer)
        
        # å†»ç»“VAE
        vae.requires_grad_(False)
        
        print(f"VAEæƒé‡æ•°æ®ç±»å‹: {next(vae.parameters()).dtype}")
        print(f"UNetæƒé‡æ•°æ®ç±»å‹: {next(unet.parameters()).dtype}")
        
        # åˆ›å»ºæµ‹è¯•æ•°æ®
        print("åˆ›å»ºæµ‹è¯•æ•°æ®...")
        batch_size = 2
        test_batch = {
            "pixel_values": torch.randn(batch_size, 3, 256, 256),
            "user_ids": torch.tensor([0, 1])
        }
        
        print("æµ‹è¯•VAEç¼–ç ...")
        # æµ‹è¯•ä¿®å¤åçš„VAEç¼–ç é€»è¾‘
        with torch.no_grad():
            pixel_values = test_batch["pixel_values"].to(accelerator.device)
            print(f"åŸå§‹æ•°æ®ç±»å‹: {pixel_values.dtype}")
            
            # åº”ç”¨æ··åˆç²¾åº¦ä¿®å¤
            if accelerator.mixed_precision == "fp16":
                pixel_values = pixel_values.half()
                print(f"è½¬æ¢åæ•°æ®ç±»å‹: {pixel_values.dtype}")
            
            latents = vae.encode(pixel_values).latents
            latents = latents * 0.18215
            
            print(f"âœ… VAEç¼–ç æˆåŠŸï¼")
            print(f"æ½œåœ¨ç©ºé—´å½¢çŠ¶: {latents.shape}")
            print(f"æ½œåœ¨ç©ºé—´æ•°æ®ç±»å‹: {latents.dtype}")
        
        # æµ‹è¯•UNetå‰å‘ä¼ æ’­
        print("æµ‹è¯•UNetå‰å‘ä¼ æ’­...")
        noise = torch.randn_like(latents)
        timesteps = torch.randint(0, 1000, (batch_size,), device=latents.device).long()
        noisy_latents = noise_scheduler.add_noise(latents, noise, timesteps)
        
        # åˆ›å»ºæ¡ä»¶
        user_ids = test_batch["user_ids"].to(accelerator.device)
        
        # UNetå‰å‘ä¼ æ’­
        noise_pred = unet(noisy_latents, timesteps, class_labels=user_ids).sample
        
        print(f"âœ… UNetå‰å‘ä¼ æ’­æˆåŠŸï¼")
        print(f"å™ªå£°é¢„æµ‹å½¢çŠ¶: {noise_pred.shape}")
        print(f"å™ªå£°é¢„æµ‹æ•°æ®ç±»å‹: {noise_pred.dtype}")
        
        print("ğŸ‰ è®­ç»ƒè„šæœ¬ä¿®å¤æµ‹è¯•é€šè¿‡ï¼")
        return True
        
    except Exception as e:
        print(f"âŒ æµ‹è¯•å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return False

if __name__ == "__main__":
    test_training_fix()
