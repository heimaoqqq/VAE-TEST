#!/usr/bin/env python3
"""
å¿«é€Ÿæµ‹è¯•ä¿®å¤åçš„æ¡ä»¶æ‰©æ•£æ¨¡å‹æ ¸å¿ƒåŠŸèƒ½
"""

import torch
import torch.nn.functional as F
from diffusers import UNet2DModel, VQModel, DDPMScheduler
import numpy as np

def test_core_functionality():
    """æµ‹è¯•æ ¸å¿ƒåŠŸèƒ½"""
    print("ğŸ” æµ‹è¯•æ ¸å¿ƒåŠŸèƒ½...")
    
    device = "cuda" if torch.cuda.is_available() else "cpu"
    print(f"ä½¿ç”¨è®¾å¤‡: {device}")
    
    try:
        # 1. åˆ›å»ºç®€åŒ–çš„ç»„ä»¶è¿›è¡Œæµ‹è¯•
        print("\n1. åˆ›å»ºæµ‹è¯•ç»„ä»¶...")
        
        # ç®€åŒ–çš„UNeté…ç½®
        unet = UNet2DModel(
            sample_size=32,  # 256//8
            in_channels=3,
            out_channels=3,
            num_class_embeds=32,  # 31ç”¨æˆ· + 1æ— æ¡ä»¶
        )
        unet = unet.to(device)
        print(f"âœ… UNetåˆ›å»ºæˆåŠŸ: {unet.config.in_channels}â†’{unet.config.out_channels}")
        
        # Scheduler
        scheduler = DDPMScheduler(
            num_train_timesteps=1000,
            beta_schedule="linear",
        )
        print(f"âœ… Scheduleråˆ›å»ºæˆåŠŸ")
        
        # 2. æµ‹è¯•è®­ç»ƒæµç¨‹
        print("\n2. æµ‹è¯•è®­ç»ƒæµç¨‹...")
        
        batch_size = 2
        # æ¨¡æ‹Ÿæ½œåœ¨ç©ºé—´æ•°æ®
        latents = torch.randn(batch_size, 3, 32, 32, device=device)
        
        # åº”ç”¨scaling (æ¨¡æ‹ŸVAEç¼–ç åçš„scaling)
        latents = latents * 0.18215
        print(f"âœ… æ½œåœ¨ç©ºé—´æ•°æ®: {latents.shape}, scalingåº”ç”¨æˆåŠŸ")
        
        # æ·»åŠ å™ªå£°
        noise = torch.randn_like(latents)
        timesteps = torch.randint(0, scheduler.config.num_train_timesteps, (batch_size,), device=latents.device)
        timesteps = timesteps.long()
        
        noisy_latents = scheduler.add_noise(latents, noise, timesteps)
        print(f"âœ… å™ªå£°æ·»åŠ æˆåŠŸ: {noisy_latents.shape}")
        
        # æ¨¡æ‹Ÿç”¨æˆ·ID
        user_ids = torch.tensor([0, 1], device=device)  # ä¸¤ä¸ªä¸åŒç”¨æˆ·
        
        # æ¨¡æ‹Ÿæ— æ¡ä»¶è®­ç»ƒæ¦‚ç‡
        uncond_prob = 0.15
        uncond_mask = torch.rand(user_ids.shape[0], device=user_ids.device) < uncond_prob
        user_ids[uncond_mask] = 31  # æ— æ¡ä»¶ID
        print(f"âœ… ç”¨æˆ·IDè®¾ç½®: {user_ids.tolist()}")
        
        # UNetå‰å‘ä¼ æ’­
        with torch.no_grad():
            noise_pred = unet(noisy_latents, timesteps, class_labels=user_ids).sample
            print(f"âœ… UNetå‰å‘ä¼ æ’­æˆåŠŸ: {noise_pred.shape}")
        
        # è®¡ç®—æŸå¤±
        loss = F.mse_loss(noise_pred.float(), noise.float(), reduction="mean")
        print(f"âœ… æŸå¤±è®¡ç®—æˆåŠŸ: {loss.item():.6f}")
        
        # 3. æµ‹è¯•æ¨ç†æµç¨‹
        print("\n3. æµ‹è¯•æ¨ç†æµç¨‹...")
        
        # è®¾ç½®æ¨ç†æ—¶é—´æ­¥
        num_inference_steps = 10  # ä½¿ç”¨è¾ƒå°‘æ­¥æ•°è¿›è¡Œå¿«é€Ÿæµ‹è¯•
        scheduler.set_timesteps(num_inference_steps, device=device)
        timesteps = scheduler.timesteps
        print(f"âœ… æ¨ç†æ—¶é—´æ­¥è®¾ç½®: {len(timesteps)} æ­¥")
        
        # åˆå§‹åŒ–éšæœºå™ªå£°
        latents = torch.randn(1, 3, 32, 32, device=device)
        latents = latents * scheduler.init_noise_sigma
        
        # æ¡ä»¶è®¾ç½®
        user_id = torch.tensor([5], device=device)  # æµ‹è¯•ç”¨æˆ·ID 5
        guidance_scale = 7.5
        
        # Classifier-free guidanceè®¾ç½®
        do_classifier_free_guidance = guidance_scale > 1.0
        if do_classifier_free_guidance:
            uncond_id = torch.tensor([31], device=device)  # æ— æ¡ä»¶ID
            class_labels = torch.cat([user_id, uncond_id])
            latents = torch.cat([latents] * 2)
        else:
            class_labels = user_id
        
        print(f"âœ… æ¡ä»¶è®¾ç½®: user_id={user_id.item()}, guidance_scale={guidance_scale}")
        
        # ç®€åŒ–çš„å»å™ªå¾ªç¯
        with torch.no_grad():
            for i, t in enumerate(timesteps[:3]):  # åªæµ‹è¯•å‰3æ­¥
                # å‡†å¤‡è¾“å…¥
                latent_model_input = scheduler.scale_model_input(latents, t)
                
                # é¢„æµ‹å™ªå£°
                noise_pred = unet(
                    latent_model_input,
                    t,
                    class_labels=class_labels,
                    return_dict=False,
                )[0]
                
                # æ‰§è¡Œguidance
                if do_classifier_free_guidance:
                    noise_pred_cond, noise_pred_uncond = noise_pred.chunk(2)
                    noise_pred = noise_pred_uncond + guidance_scale * (noise_pred_cond - noise_pred_uncond)
                    # åªä¿ç•™æ¡ä»¶éƒ¨åˆ†çš„latents
                    current_latents = latents[:1]
                else:
                    current_latents = latents
                
                # å»å™ªæ­¥éª¤
                latents_new = scheduler.step(noise_pred, t, current_latents, return_dict=False)[0]
                
                if do_classifier_free_guidance:
                    latents = torch.cat([latents_new] * 2)
                else:
                    latents = latents_new
                
                print(f"   æ­¥éª¤ {i+1}/3: t={t.item()}, latentså½¢çŠ¶={latents_new.shape}")
        
        print(f"âœ… æ¨ç†æµç¨‹æµ‹è¯•æˆåŠŸ")
        
        # 4. æµ‹è¯•scalingä¸€è‡´æ€§
        print("\n4. æµ‹è¯•scalingä¸€è‡´æ€§...")
        
        # æ¨¡æ‹Ÿæœ€ç»ˆlatents
        final_latents = latents_new if not do_classifier_free_guidance else latents_new
        
        # åº”ç”¨è§£ç å‰çš„scaling
        unscaled_latents = final_latents / 0.18215
        print(f"âœ… è§£ç å‰scaling: {final_latents.shape} -> {unscaled_latents.shape}")
        
        print("\nğŸ‰ æ‰€æœ‰æ ¸å¿ƒåŠŸèƒ½æµ‹è¯•é€šè¿‡ï¼")
        return True
        
    except Exception as e:
        print(f"âŒ æµ‹è¯•å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return False

def main():
    print("ğŸš€ å¼€å§‹å¿«é€Ÿæµ‹è¯•ä¿®å¤åçš„æ¡ä»¶æ‰©æ•£æ¨¡å‹...")
    print("=" * 60)
    
    success = test_core_functionality()
    
    print("\n" + "=" * 60)
    if success:
        print("ğŸ‰ å¿«é€Ÿæµ‹è¯•é€šè¿‡ï¼ä¿®å¤çš„ä»£ç åº”è¯¥å¯ä»¥æ­£å¸¸å·¥ä½œã€‚")
        print("\nğŸ“‹ å…³é”®ä¿®å¤ç‚¹éªŒè¯:")
        print("âœ… UNeté€šé“æ•°é…ç½®ç»Ÿä¸€ (3â†’3)")
        print("âœ… VAE scaling factorç»Ÿä¸€ (0.18215)")
        print("âœ… Classifier-free guidanceé€»è¾‘æ­£ç¡®")
        print("âœ… APIè°ƒç”¨æ–¹å¼æ­£ç¡®")
        print("\nğŸš€ å¯ä»¥åœ¨äº‘æœåŠ¡å™¨ä¸Šè¿›è¡Œå®Œæ•´è®­ç»ƒæµ‹è¯•ï¼")
    else:
        print("âŒ å¿«é€Ÿæµ‹è¯•å¤±è´¥ï¼Œè¯·æ£€æŸ¥ä»£ç ä¿®å¤")

if __name__ == "__main__":
    main()
