#!/usr/bin/env python3
"""
æµ‹è¯•æ··åˆç²¾åº¦ä¿®å¤
"""

import torch
from diffusers import VQModel
from accelerate import Accelerator

def test_mixed_precision_fix():
    print("ğŸ§ª æµ‹è¯•æ··åˆç²¾åº¦ä¿®å¤...")
    
    # åˆå§‹åŒ–accelerator with fp16
    accelerator = Accelerator(mixed_precision="fp16")
    print(f"Mixed precision: {accelerator.mixed_precision}")
    
    # åŠ è½½VAEæ¨¡å‹
    print("åŠ è½½VAEæ¨¡å‹...")
    vae = VQModel.from_pretrained("CompVis/ldm-celebahq-256", subfolder="vqvae")
    
    # å‡†å¤‡æ¨¡å‹ï¼ˆè¿™ä¼šåº”ç”¨æ··åˆç²¾åº¦ï¼‰
    vae = accelerator.prepare(vae)
    vae.requires_grad_(False)
    
    # åˆ›å»ºæµ‹è¯•æ•°æ®
    print("åˆ›å»ºæµ‹è¯•æ•°æ®...")
    batch_size = 2
    test_images = torch.randn(batch_size, 3, 256, 256)
    
    print(f"åŸå§‹å›¾åƒæ•°æ®ç±»å‹: {test_images.dtype}")
    print(f"VAEæƒé‡æ•°æ®ç±»å‹: {next(vae.parameters()).dtype}")
    
    # æµ‹è¯•ä¿®å¤åçš„ç¼–ç é€»è¾‘
    print("æµ‹è¯•VAEç¼–ç ...")
    try:
        with torch.no_grad():
            pixel_values = test_images.to(accelerator.device)
            print(f"ç§»åŠ¨åˆ°è®¾å¤‡åæ•°æ®ç±»å‹: {pixel_values.dtype}")
            
            # åº”ç”¨æ··åˆç²¾åº¦ä¿®å¤
            if accelerator.mixed_precision == "fp16":
                pixel_values = pixel_values.half()
                print(f"è½¬æ¢ä¸ºfp16åæ•°æ®ç±»å‹: {pixel_values.dtype}")
            
            latents = vae.encode(pixel_values).latents
            latents = latents * 0.18215
            
            print(f"âœ… VAEç¼–ç æˆåŠŸï¼")
            print(f"æ½œåœ¨ç©ºé—´å½¢çŠ¶: {latents.shape}")
            print(f"æ½œåœ¨ç©ºé—´æ•°æ®ç±»å‹: {latents.dtype}")
            
    except Exception as e:
        print(f"âŒ VAEç¼–ç å¤±è´¥: {e}")
        return False
    
    print("ğŸ‰ æ··åˆç²¾åº¦ä¿®å¤æµ‹è¯•é€šè¿‡ï¼")
    return True

if __name__ == "__main__":
    test_mixed_precision_fix()
