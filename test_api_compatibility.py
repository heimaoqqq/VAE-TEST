#!/usr/bin/env python3
"""
æµ‹è¯•diffusers APIå…¼å®¹æ€§å’Œä¿®å¤åçš„æ¡ä»¶æ‰©æ•£æ¨¡å‹
"""

import torch
import os
import argparse
from diffusers import UNet2DModel, VQModel, DDPMScheduler
import numpy as np
from PIL import Image
import time

def test_unet_api():
    """æµ‹è¯•UNet2DModelçš„APIå…¼å®¹æ€§"""
    print("ğŸ” æµ‹è¯•UNet2DModel APIå…¼å®¹æ€§...")
    
    try:
        # åˆ›å»ºæµ‹è¯•UNet
        unet = UNet2DModel(
            sample_size=32,  # 256//8 = 32
            in_channels=3,
            out_channels=3,
            layers_per_block=2,
            block_out_channels=(128, 256, 512, 512),
            down_block_types=(
                "DownBlock2D", 
                "DownBlock2D", 
                "AttnDownBlock2D", 
                "DownBlock2D"
            ),
            up_block_types=(
                "UpBlock2D", 
                "AttnUpBlock2D", 
                "UpBlock2D", 
                "UpBlock2D"
            ),
            num_class_embeds=32,  # 31ç”¨æˆ· + 1æ— æ¡ä»¶
        )
        
        print(f"âœ… UNetåˆ›å»ºæˆåŠŸ")
        print(f"   - è¾“å…¥é€šé“: {unet.config.in_channels}")
        print(f"   - è¾“å‡ºé€šé“: {unet.config.out_channels}")
        print(f"   - ç±»åˆ«åµŒå…¥æ•°: {unet.config.num_class_embeds}")
        
        # æµ‹è¯•forwardæ–¹æ³•
        device = "cuda" if torch.cuda.is_available() else "cpu"
        unet = unet.to(device)
        
        # åˆ›å»ºæµ‹è¯•è¾“å…¥
        batch_size = 2
        latents = torch.randn(batch_size, 3, 32, 32, device=device)
        timesteps = torch.randint(0, 1000, (batch_size,), device=device)
        class_labels = torch.tensor([0, 1], device=device)
        
        print(f"   - æµ‹è¯•è¾“å…¥å½¢çŠ¶: {latents.shape}")
        print(f"   - æ—¶é—´æ­¥å½¢çŠ¶: {timesteps.shape}")
        print(f"   - ç±»åˆ«æ ‡ç­¾å½¢çŠ¶: {class_labels.shape}")
        
        # æµ‹è¯•ä¸åŒçš„APIè°ƒç”¨æ–¹å¼
        with torch.no_grad():
            # æ–¹å¼1: ä½¿ç”¨class_labelså‚æ•°
            try:
                output1 = unet(latents, timesteps, class_labels=class_labels)
                if hasattr(output1, 'sample'):
                    noise_pred1 = output1.sample
                else:
                    noise_pred1 = output1
                print(f"âœ… æ–¹å¼1æˆåŠŸ (class_labels): è¾“å‡ºå½¢çŠ¶ {noise_pred1.shape}")
            except Exception as e:
                print(f"âŒ æ–¹å¼1å¤±è´¥ (class_labels): {e}")
            
            # æ–¹å¼2: ä½¿ç”¨ä½ç½®å‚æ•°
            try:
                output2 = unet(latents, timesteps, class_labels)
                if hasattr(output2, 'sample'):
                    noise_pred2 = output2.sample
                else:
                    noise_pred2 = output2
                print(f"âœ… æ–¹å¼2æˆåŠŸ (ä½ç½®å‚æ•°): è¾“å‡ºå½¢çŠ¶ {noise_pred2.shape}")
            except Exception as e:
                print(f"âŒ æ–¹å¼2å¤±è´¥ (ä½ç½®å‚æ•°): {e}")
            
            # æ–¹å¼3: æ£€æŸ¥è¿”å›å€¼ç±»å‹
            try:
                output3 = unet(latents, timesteps, class_labels=class_labels, return_dict=False)
                if isinstance(output3, tuple):
                    noise_pred3 = output3[0]
                else:
                    noise_pred3 = output3
                print(f"âœ… æ–¹å¼3æˆåŠŸ (return_dict=False): è¾“å‡ºå½¢çŠ¶ {noise_pred3.shape}")
            except Exception as e:
                print(f"âŒ æ–¹å¼3å¤±è´¥ (return_dict=False): {e}")
        
        return True
        
    except Exception as e:
        print(f"âŒ UNet APIæµ‹è¯•å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return False

def test_vae_api():
    """æµ‹è¯•VQModelçš„APIå…¼å®¹æ€§"""
    print("\nğŸ” æµ‹è¯•VQModel APIå…¼å®¹æ€§...")
    
    try:
        # åŠ è½½é¢„è®­ç»ƒVAE
        vae = VQModel.from_pretrained("CompVis/ldm-celebahq-256", subfolder="vqvae")
        print(f"âœ… VAEåŠ è½½æˆåŠŸ")
        print(f"   - æ½œåœ¨é€šé“æ•°: {vae.config.latent_channels}")
        print(f"   - block_out_channels: {vae.config.block_out_channels}")
        
        # æ£€æŸ¥scaling_factor
        if hasattr(vae.config, 'scaling_factor'):
            print(f"   - scaling_factor: {vae.config.scaling_factor}")
        else:
            print(f"   - scaling_factor: æœªè®¾ç½®ï¼Œä½¿ç”¨é»˜è®¤å€¼0.18215")
        
        device = "cuda" if torch.cuda.is_available() else "cpu"
        vae = vae.to(device)
        
        # æµ‹è¯•ç¼–ç è§£ç 
        test_image = torch.randn(1, 3, 256, 256, device=device)
        
        with torch.no_grad():
            # æµ‹è¯•ç¼–ç 
            encoded = vae.encode(test_image)
            if hasattr(encoded, 'latents'):
                latents = encoded.latents
            else:
                latents = encoded
            print(f"âœ… ç¼–ç æˆåŠŸ: {test_image.shape} -> {latents.shape}")
            
            # æµ‹è¯•scaling
            scaled_latents = latents * 0.18215
            print(f"âœ… ScalingæˆåŠŸ: {scaled_latents.shape}")
            
            # æµ‹è¯•è§£ç 
            unscaled_latents = scaled_latents / 0.18215
            decoded = vae.decode(unscaled_latents)
            if hasattr(decoded, 'sample'):
                decoded_image = decoded.sample
            else:
                decoded_image = decoded
            print(f"âœ… è§£ç æˆåŠŸ: {unscaled_latents.shape} -> {decoded_image.shape}")
        
        return True
        
    except Exception as e:
        print(f"âŒ VAE APIæµ‹è¯•å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return False

def test_scheduler_api():
    """æµ‹è¯•DDPMSchedulerçš„APIå…¼å®¹æ€§"""
    print("\nğŸ” æµ‹è¯•DDPMScheduler APIå…¼å®¹æ€§...")
    
    try:
        scheduler = DDPMScheduler(
            num_train_timesteps=1000,
            beta_schedule="linear",
        )
        print(f"âœ… Scheduleråˆ›å»ºæˆåŠŸ")
        print(f"   - è®­ç»ƒæ—¶é—´æ­¥æ•°: {scheduler.config.num_train_timesteps}")
        print(f"   - Betaè°ƒåº¦: {scheduler.config.beta_schedule}")
        
        device = "cuda" if torch.cuda.is_available() else "cpu"
        
        # æµ‹è¯•æ·»åŠ å™ªå£°
        latents = torch.randn(2, 3, 32, 32, device=device)
        noise = torch.randn_like(latents)
        timesteps = torch.randint(0, 1000, (2,), device=device)
        
        noisy_latents = scheduler.add_noise(latents, noise, timesteps)
        print(f"âœ… æ·»åŠ å™ªå£°æˆåŠŸ: {latents.shape} -> {noisy_latents.shape}")
        
        # æµ‹è¯•æ¨ç†è®¾ç½®
        scheduler.set_timesteps(50, device=device)
        print(f"âœ… è®¾ç½®æ¨ç†æ—¶é—´æ­¥æˆåŠŸ: {len(scheduler.timesteps)} æ­¥")
        
        # æµ‹è¯•å»å™ªæ­¥éª¤
        noise_pred = torch.randn_like(latents)
        t = scheduler.timesteps[0]
        
        step_output = scheduler.step(noise_pred, t, latents, return_dict=False)
        if isinstance(step_output, tuple):
            prev_sample = step_output[0]
        else:
            prev_sample = step_output.prev_sample
        print(f"âœ… å»å™ªæ­¥éª¤æˆåŠŸ: {latents.shape} -> {prev_sample.shape}")
        
        return True
        
    except Exception as e:
        print(f"âŒ Scheduler APIæµ‹è¯•å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return False

def main():
    parser = argparse.ArgumentParser(description="æµ‹è¯•diffusers APIå…¼å®¹æ€§")
    parser.add_argument("--skip_vae", action="store_true", help="è·³è¿‡VAEæµ‹è¯•ï¼ˆéœ€è¦ç½‘ç»œä¸‹è½½ï¼‰")
    args = parser.parse_args()
    
    print("ğŸš€ å¼€å§‹æµ‹è¯•diffusers APIå…¼å®¹æ€§...")
    print("=" * 60)
    
    # æµ‹è¯•1: UNet API
    unet_ok = test_unet_api()
    
    # æµ‹è¯•2: VAE APIï¼ˆå¯é€‰ï¼‰
    if not args.skip_vae:
        vae_ok = test_vae_api()
    else:
        print("\nâ­ï¸  è·³è¿‡VAEæµ‹è¯•")
        vae_ok = True
    
    # æµ‹è¯•3: Scheduler API
    scheduler_ok = test_scheduler_api()
    
    print("\n" + "=" * 60)
    if unet_ok and vae_ok and scheduler_ok:
        print("ğŸ‰ æ‰€æœ‰APIå…¼å®¹æ€§æµ‹è¯•é€šè¿‡ï¼")
        print("\nğŸ“‹ å»ºè®®çš„APIä½¿ç”¨æ–¹å¼:")
        print("1. UNetè°ƒç”¨: unet(latents, timesteps, class_labels=class_labels).sample")
        print("2. VAEç¼–ç : vae.encode(images).latents")
        print("3. VAEè§£ç : vae.decode(latents).sample")
        print("4. Scheduleræ­¥éª¤: scheduler.step(noise_pred, t, latents, return_dict=False)[0]")
    else:
        print("âŒ éƒ¨åˆ†APIæµ‹è¯•å¤±è´¥ï¼Œè¯·æ£€æŸ¥diffusersç‰ˆæœ¬å’Œä»£ç å®ç°")
    
    print(f"\nğŸ“¦ å½“å‰ç¯å¢ƒä¿¡æ¯:")
    try:
        import diffusers
        print(f"   - diffusersç‰ˆæœ¬: {diffusers.__version__}")
    except:
        print("   - diffusersç‰ˆæœ¬: æœªçŸ¥")
    
    try:
        import torch
        print(f"   - torchç‰ˆæœ¬: {torch.__version__}")
        print(f"   - CUDAå¯ç”¨: {torch.cuda.is_available()}")
        if torch.cuda.is_available():
            print(f"   - CUDAç‰ˆæœ¬: {torch.version.cuda}")
    except:
        print("   - torchç‰ˆæœ¬: æœªçŸ¥")

if __name__ == "__main__":
    main()
